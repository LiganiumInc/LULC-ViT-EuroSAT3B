
# ğŸ›°ï¸ Land Use and Land Cover (LULC) Classification with Vision Transformers

This project revisits and rebuilds a previous Land Use and Land Cover (LULC) classification task on the EuroSAT dataset, using **Vision Transformers (ViT)** and **modern PyTorch best practices**.

It covers everything from dataset loading, preprocessing, training with transfer learning, to saving and using the model for inference â€” all in a clean, modular structure powered by **Pipenv** and reproducible configs.

## ğŸ“œ  Read  my blog post here

Part 1 : [How I Rebuilt My First LULC Project with a Vision Transformer and Clean Code](https://medium.com/@bernardinligan/how-i-rebuilt-my-first-lulc-project-with-a-vision-transformer-and-clean-code-aa9a06094c89)

Part 2 : [From Model to Map: Automating Land Use Classification with Vision Transformers and Google EarthÂ Engine](https://medium.com/@bernardinligan/from-model-to-map-automating-land-use-classification-with-vision-transformers-and-google-earth-9a5510215054)

## ğŸ“‚ Project Structure

```

â”œâ”€â”€ config.yaml           # All training and data parameters
â”œâ”€â”€ data/                 # Folder for the EuroSAT dataset (structure preserved, content ignored by Git)
â”œâ”€â”€ datafactory.py        # Custom Dataset and transforms
â”œâ”€â”€ engine.py             # Training and evaluation loops
â”œâ”€â”€ LULC\_3BIMG\_VIT.ipynb  # Main training notebook
â”œâ”€â”€ outputs/              # Folder to save models, plots, reports (content ignored by Git)
â”œâ”€â”€ utils.py              # Utilities (plotting, seeding, inference tools)
â”œâ”€â”€ Pipfile / Pipfile.lock # Reproducible environment with Pipenv
â””â”€â”€ .gitignore

````

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/LiganiumInc/LULC-ViT-EuroSAT3B.git
cd LULC-ViT-EuroSAT3B
````

### 2. Set up the Environment

```bash
# Make sure Pipenv is installed
pip install pipenv

# Create and activate virtual environment
export PIPENV_VENV_IN_PROJECT=1
pipenv install
pipenv shell
```

### 3. Download the EuroSAT RGB Dataset

* Link: [https://github.com/phelber/EuroSAT](https://github.com/phelber/EuroSAT)
* Extract into the following structure:

```
data/
â””â”€â”€ EuroSAT/
    â””â”€â”€ 2750/
        â”œâ”€â”€ AnnualCrop/
        â”œâ”€â”€ Forest/
        â””â”€â”€ ...
```

---

## âš™ï¸ Configuration

All settings can be found in `config.yaml`. Example:

```yaml
data_dir: "./data/EuroSAT/2750/"
batch_size: 32
num_epochs: 10
lr: 0.001
weight_decay: 0.05
percentage_per_class: 0.3
```

---

## ğŸ§  Model: Vision Transformer (ViT)

We use the pretrained `vit_b_16` from `torchvision.models`, and fine-tune it to classify 10 LULC categories.



## ğŸ“Š Outputs

After training, you'll find:

* `best_model.pth`: The saved fine-tuned ViT model
* `loss_acc_curves.png`: Visual training metrics
* `train_report.txt`: Final performance logs

---

## ğŸ§‘â€ğŸ’» Author

**Bernardin Ligan**
PhD Student in AI & Remote Sensing

ğŸŒ Passionate about geospatial ML, open science, and SDGs 

---

## ğŸ“œ License

This project is open-source and available under the [MIT License](LICENSE).

```

